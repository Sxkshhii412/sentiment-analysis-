{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b50610",
   "metadata": {},
   "source": [
    "<H1>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;         MAJOR PROJECT</H1>\n",
    "\n",
    "<H2>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SENTIMENT ANALYSIS ON IMDB REVIEWS </H2>\n",
    "\n",
    "\n",
    "You can download the dataset from the Kaggle link below: https://www.kaggle.com/ymanojkumar023/kumarmanoj-bag-of-words-meets-bags-of-popcorn \n",
    "\n",
    "Dataset : labeledTrainData.tsv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f772e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "52b4d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load our dataset here..\n",
    "df = pd.read_csv('labeledTrainData.tsv',  delimiter=\"\\t\", quoting=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d736f9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the head of the dataset:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0be5437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "553cff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e767dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since stopwords aren't used in NLP we have to clear stopwords. For this purpose we must download stopword wordset from nltk library..\n",
    "# We do this operation using nltk module..\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5748918b",
   "metadata": {},
   "source": [
    "## * * * * Data Cleaning Operations * * * *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb420a",
   "metadata": {},
   "source": [
    "### First, we will delete HTML tags from review sentences using the BeautifulSoup module.\n",
    "\n",
    "To explain how these processes are done, first let's choose a single review and see how it is done for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52044274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I dont know why people think this is such a bad movie. Its got a pretty good plot, some good action, and the change of location for Harry does not hurt either. Sure some of its offensive and gratuitous but this is not the only movie like that. Eastwood is in good form as Dirty Harry, and I liked Pat Hingle in this movie as the small town cop. If you liked DIRTY HARRY, then you should see this one, its a lot better than THE DEAD POOL. 4/5\"'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.review[5]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "68d67c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I dont know why people think this is such a bad movie. Its got a pretty good plot, some good action, and the change of location for Harry does not hurt either. Sure some of its offensive and gratuitous but this is not the only movie like that. Eastwood is in good form as Dirty Harry, and I liked Pat Hingle in this movie as the small town cop. If you liked DIRTY HARRY, then you should see this one, its a lot better than THE DEAD POOL. 4/5\"'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear HTML tags..\n",
    "sample = BeautifulSoup(sample).get_text()\n",
    "sample  # After the HTML tags are cleared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a547704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I dont know why people think this is such a bad movie  Its got a pretty good plot  some good action  and the change of location for Harry does not hurt either  Sure some of its offensive and gratuitous but this is not the only movie like that  Eastwood is in good form as Dirty Harry  and I liked Pat Hingle in this movie as the small town cop  If you liked DIRTY HARRY  then you should see this one  its a lot better than THE DEAD POOL      '"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we clean it from punctuation and numbers - using regex..\n",
    "sample = re.sub(\"[^a-zA-Z]\",' ',sample)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64917f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' i dont know why people think this is such a bad movie  its got a pretty good plot  some good action  and the change of location for harry does not hurt either  sure some of its offensive and gratuitous but this is not the only movie like that  eastwood is in good form as dirty harry  and i liked pat hingle in this movie as the small town cop  if you liked dirty harry  then you should see this one  its a lot better than the dead pool      '"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we convert it to lowercase, since our machine learning algorithms think capitalized letters with different words\n",
    "# and this may result mistakes..\n",
    "sample = sample.lower()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6f3c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords (stopwords are the words like the, is, are not to be used by AI. These are grammar words..)\n",
    "# First we split the words with split and convert them to a list. Our goal is to remove stopwords..\n",
    "sample = sample.split()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6fdd8373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'dont',\n",
       " 'know',\n",
       " 'why',\n",
       " 'people',\n",
       " 'think',\n",
       " 'this',\n",
       " 'is',\n",
       " 'such',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'movie',\n",
       " 'its',\n",
       " 'got',\n",
       " 'a',\n",
       " 'pretty',\n",
       " 'good',\n",
       " 'plot',\n",
       " 'some',\n",
       " 'good',\n",
       " 'action',\n",
       " 'and',\n",
       " 'the',\n",
       " 'change',\n",
       " 'of',\n",
       " 'location',\n",
       " 'for',\n",
       " 'harry',\n",
       " 'does',\n",
       " 'not',\n",
       " 'hurt',\n",
       " 'either',\n",
       " 'sure',\n",
       " 'some',\n",
       " 'of',\n",
       " 'its',\n",
       " 'offensive',\n",
       " 'and',\n",
       " 'gratuitous',\n",
       " 'but',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'the',\n",
       " 'only',\n",
       " 'movie',\n",
       " 'like',\n",
       " 'that',\n",
       " 'eastwood',\n",
       " 'is',\n",
       " 'in',\n",
       " 'good',\n",
       " 'form',\n",
       " 'as',\n",
       " 'dirty',\n",
       " 'harry',\n",
       " 'and',\n",
       " 'i',\n",
       " 'liked',\n",
       " 'pat',\n",
       " 'hingle',\n",
       " 'in',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'as',\n",
       " 'the',\n",
       " 'small',\n",
       " 'town',\n",
       " 'cop',\n",
       " 'if',\n",
       " 'you',\n",
       " 'liked',\n",
       " 'dirty',\n",
       " 'harry',\n",
       " 'then',\n",
       " 'you',\n",
       " 'should',\n",
       " 'see',\n",
       " 'this',\n",
       " 'one',\n",
       " 'its',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'better',\n",
       " 'than',\n",
       " 'the',\n",
       " 'dead',\n",
       " 'pool']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d729b143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a9a90aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dont',\n",
       " 'know',\n",
       " 'people',\n",
       " 'think',\n",
       " 'bad',\n",
       " 'movie',\n",
       " 'got',\n",
       " 'pretty',\n",
       " 'good',\n",
       " 'plot',\n",
       " 'good',\n",
       " 'action',\n",
       " 'change',\n",
       " 'location',\n",
       " 'harry',\n",
       " 'hurt',\n",
       " 'either',\n",
       " 'sure',\n",
       " 'offensive',\n",
       " 'gratuitous',\n",
       " 'movie',\n",
       " 'like',\n",
       " 'eastwood',\n",
       " 'good',\n",
       " 'form',\n",
       " 'dirty',\n",
       " 'harry',\n",
       " 'liked',\n",
       " 'pat',\n",
       " 'hingle',\n",
       " 'movie',\n",
       " 'small',\n",
       " 'town',\n",
       " 'cop',\n",
       " 'liked',\n",
       " 'dirty',\n",
       " 'harry',\n",
       " 'see',\n",
       " 'one',\n",
       " 'lot',\n",
       " 'better',\n",
       " 'dead',\n",
       " 'pool']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample without stopwords\n",
    "swords = set(stopwords.words(\"english\"))                      # conversion into set for fast searching\n",
    "sample = [w for w in sample if w not in swords]               \n",
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d57027ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49b90371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After describing the cleanup process, we now batch clean the reviews in our entire dataframe in a loop\n",
    "# for this purpose we first create a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "66ec33e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(review):\n",
    "    # without HTML tags\n",
    "    review = BeautifulSoup(review).get_text()\n",
    "    # without punctuation and numbers\n",
    "    review = re.sub(\"[^a-zA-Z]\",' ',review)\n",
    "    # lowercase and splitting to eliminate stopwords\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    # without stopwords\n",
    "    swords = set(stopwords.words(\"english\"))                      \n",
    "    review = [w for w in review if w not in swords]               \n",
    "    # we join splitted paragraphs with join before return..\n",
    "    return(\" \".join(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "594912eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of reviews processed = 1000\n",
      "No of reviews processed = 2000\n",
      "No of reviews processed = 3000\n",
      "No of reviews processed = 4000\n",
      "No of reviews processed = 5000\n",
      "No of reviews processed = 6000\n",
      "No of reviews processed = 7000\n",
      "No of reviews processed = 8000\n",
      "No of reviews processed = 9000\n",
      "No of reviews processed = 10000\n",
      "No of reviews processed = 11000\n",
      "No of reviews processed = 12000\n",
      "No of reviews processed = 13000\n",
      "No of reviews processed = 14000\n",
      "No of reviews processed = 15000\n",
      "No of reviews processed = 16000\n",
      "No of reviews processed = 17000\n",
      "No of reviews processed = 18000\n",
      "No of reviews processed = 19000\n",
      "No of reviews processed = 20000\n",
      "No of reviews processed = 21000\n",
      "No of reviews processed = 22000\n",
      "No of reviews processed = 23000\n",
      "No of reviews processed = 24000\n",
      "No of reviews processed = 25000\n"
     ]
    }
   ],
   "source": [
    "# We clean our training data with the help of the above function:\n",
    "# We can see the status of the review process by printing a line after every 1000 reviews.\n",
    "\n",
    "train_x_tum = []\n",
    "for r in range(len(df[\"review\"])):        \n",
    "    if (r+1)%1000 == 0:        \n",
    "        print(\"No of reviews processed =\", r+1)\n",
    "    train_x_tum.append(process(df[\"review\"][r]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d2a1c0",
   "metadata": {},
   "source": [
    "### Train, test split..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d340b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to split our data as train and test..\n",
    "x = train_x_tum\n",
    "y = np.array(df[\"sentiment\"])\n",
    "\n",
    "# train test split\n",
    "train_x, test_x, y_train, y_test = train_test_split(x,y, test_size = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590370e4",
   "metadata": {},
   "source": [
    "### We are building our Bag of Words !\n",
    "\n",
    "We have cleaned our data, but for the artificial intelligence to work, it is necessary to convert this text-based data into numbers and a matrix called bag of words. Here we use the CountVectorizer tool in sklearn for this purpose:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d80813",
   "metadata": {},
   "source": [
    "<IMG src=\"bag.jpg\" width=\"900\" height=\"900\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cb5e8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the countvectorizer function in sklearn, we create a bag of words with a maximum of 5000 words...\n",
    "vectorizer = CountVectorizer( max_features = 5000 )\n",
    "\n",
    "# We convert our train data to feature vector matrix\n",
    "train_x = vectorizer.fit_transform(train_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6e9925e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22500x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1777199 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a05067bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are converting it to array because it wants array for fit operation..\n",
    "train_x = train_x.toarray()\n",
    "train_y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bcddaafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22500, 5000), (22500,))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c550376c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d658fe33",
   "metadata": {},
   "source": [
    "### We build and fit a Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0029a57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "model.fit(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04f2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b440b1a5",
   "metadata": {},
   "source": [
    "### Now it's time for our test data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5433e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert our test data to feature vector matrix\n",
    "test_xx = vectorizer.transform(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d7bbfd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2500x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 198060 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b1959911",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xx = test_xx.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a7cf4853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 5000)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_xx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0be3d",
   "metadata": {},
   "source": [
    "#### Now let's predict.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "54e913a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(test_xx)\n",
    "acc = roc_auc_score(y_test, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "82bbd16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: %  83.52642873074922\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: % \", acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd665d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733f4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a750489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b3c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66db775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3c6d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a2173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31354a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8023d0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d4210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13722a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035d62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c02ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92cc7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362f38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62913061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2de634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb8202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37391e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fe125b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
